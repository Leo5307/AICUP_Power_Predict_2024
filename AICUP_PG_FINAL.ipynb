{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list --format=freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_donghua_df = pd.read_csv(\"./data/C0Z100_2024.csv\")\n",
    "print(weather_donghua_df.columns)\n",
    "\n",
    "weather_donghua_df['datetime'] = pd.to_datetime(weather_donghua_df['Unnamed: 0'], format='%m/%d/%Y %H:%M')\n",
    "weather_donghua_df['formatted_datetime'] = weather_donghua_df['datetime'].dt.strftime('%Y%m%d%H')\n",
    "print(weather_donghua_df[['Unnamed: 0', 'formatted_datetime']])\n",
    "print(weather_donghua_df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_dict = weather_donghua_df.set_index('formatted_datetime').T.to_dict()\n",
    "\n",
    "# 打印前幾個項目檢查\n",
    "for key, value in list(weather_data_dict.items())[:]:\n",
    "    print(f\"Key: {key}\")\n",
    "    print(f\"Value: {value}\")\n",
    "    print()\n",
    "    \n",
    "print(weather_data_dict['2024010101']['TxSoil0cm'])\n",
    "print(weather_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = os.listdir('./36_TrainingData_Additional_V2')\n",
    "print(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 檢查並創建目標文件夾\n",
    "output_folder = './complete_Training_Data/'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    print(f\"目標文件夾 {output_folder} 已創建\")\n",
    "\n",
    "# 處理檔案\n",
    "for doc_name in os.listdir('./TrainingData'):\n",
    "    df = pd.read_csv('./TrainingData/' + doc_name)\n",
    "    print(\"df\", len(df))\n",
    "    device_name = doc_name.split('_')[0]\n",
    "    \n",
    "    for add_doc_name in list_of_files:\n",
    "        add_device_name = add_doc_name.split('_')[0]\n",
    "        if device_name == add_device_name:\n",
    "            add_df = pd.read_csv('./36_TrainingData_Additional_V2/' + add_doc_name)\n",
    "            print(\"add_df\", len(add_df))\n",
    "            df = pd.concat([df, add_df])\n",
    "            print(\"df\", len(df))\n",
    "    \n",
    "    save_name = device_name + '_complete_Train.csv'\n",
    "    print(\"saving to:\", save_name)\n",
    "    df.to_csv(output_folder + save_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  觀察資料\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 載入所有 L1 到 L17 的訓練資料\n",
    "# LookBackNum = 12 #LSTM往前看的筆數\n",
    "# ForecastNum = 48 #預測筆數\n",
    "dataframes = []\n",
    "for i in range(1, 18):\n",
    "    # filename = f'./TrainingData/L{i}_Train.csv'\n",
    "    filename = f'./complete_Training_Data/L{i}_complete_Train.csv'\n",
    "    df = pd.read_csv(filename, encoding='utf-8')\n",
    "    print(len(df))\n",
    "    dataframes.append(df)\n",
    "\n",
    "# 合併所有 DataFrame\n",
    "SourceData = pd.concat(dataframes, ignore_index=True)\n",
    "print(len(SourceData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SourceData)\n",
    "print(SourceData.columns)   \n",
    "SourceData['DateTime'] = pd.to_datetime(SourceData['DateTime'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "# 格式化為 YYYYMMDDHH\n",
    "SourceData['FormattedDateTime'] = SourceData['DateTime'].dt.strftime('%Y%m%d%H')\n",
    "\n",
    "# 檢查結果\n",
    "print(SourceData[['DateTime', 'FormattedDateTime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(SourceData))\n",
    "count = 0\n",
    "# count = 0\n",
    "for index, data in SourceData.iterrows():\n",
    "    formatted_datetime = data['FormattedDateTime']\n",
    "    \n",
    "    # 檢查 weather_data_dict 是否包含該日期時間\n",
    "    if formatted_datetime in weather_data_dict:\n",
    "        SourceData.loc[index, 'WSGust'] = weather_data_dict[formatted_datetime]['WSGust']\n",
    "        SourceData.loc[index, 'WDGust'] = weather_data_dict[formatted_datetime]['WDGust']\n",
    "        SourceData.loc[index, 'GloblRad'] = weather_data_dict[formatted_datetime]['GloblRad']\n",
    "        SourceData.loc[index, 'Precp'] = weather_data_dict[formatted_datetime]['Precp']\n",
    "        SourceData.loc[index, 'TxSoil0cm'] = weather_data_dict[formatted_datetime]['TxSoil0cm']\n",
    "        SourceData.loc[index, 'TxSoil10cm'] = weather_data_dict[formatted_datetime]['TxSoil10cm']\n",
    "        SourceData.loc[index, 'TxSoil20cm'] = weather_data_dict[formatted_datetime]['TxSoil20cm'] \n",
    "        SourceData.loc[index, 'TxSoil50cm'] = weather_data_dict[formatted_datetime]['TxSoil50cm']\n",
    "        SourceData.loc[index, 'TxSoil100cm'] = weather_data_dict[formatted_datetime]['TxSoil100cm']\n",
    "    else:\n",
    "        print(f'{formatted_datetime} not found in weather_data_dict')\n",
    "\n",
    "    count += 1\n",
    "    # if count % 100 == 0:\n",
    "    #     break\n",
    "    print(f'Processing row {count}/{len(SourceData)}')\n",
    "\n",
    "# 儲存最後的結果\n",
    "SourceData.to_csv('full_information_sources_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SourceData = pd.read_csv('full_information_sources_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SourceData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 顯示相關性排序(Linear)\n",
    "# import pandas as pd\n",
    "\n",
    "# # 計算相關係數\n",
    "# corr_matrix = SourceData.corr()\n",
    "# sunlight_corr = corr_matrix[\"Sunlight(Lux)\"].sort_values(ascending=False)\n",
    "\n",
    "# # 顯示相關性排序\n",
    "# print(sunlight_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接下來把 complete_Training_Data文件夾 輸入到微氣候數據處理程序 產出 CompleteAVG 和 CompleteIncompleteAVG 兩個文件夾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 欄位名稱列表\n",
    "column_names = [\n",
    "    \"DateTime\", \"WindSpeed(m/s)\", \"Pressure(hpa)\", \n",
    "    \"Temperature(°C)\", \"Humidity(%)\", \"Sunlight(Lux)\", \"Power(mW)\",\n",
    "    \"WSGust\", \"WDGust\", \"GloblRad\", \"Precp\", \n",
    "    \"TxSoil0cm\", \"TxSoil10cm\", \"TxSoil20cm\", \"TxSoil50cm\", \"TxSoil100cm\"\n",
    "]\n",
    "\n",
    "# 讀取時指定欄位名稱\n",
    "dataframes = []\n",
    "for i in range(1, 18):\n",
    "    if i < 10:\n",
    "        location_code = f'0{i}'    \n",
    "    else:\n",
    "        location_code = f'{i}'\n",
    "    filename = f'./CompleteAVG/AvgDATA_'+location_code+'.csv'\n",
    "    \n",
    "    # 指定欄位名稱讀取\n",
    "    df = pd.read_csv(filename, encoding='utf-8', names=column_names)\n",
    "    print(len(df))\n",
    "    dataframes.append(df)\n",
    "\n",
    "# 合併所有 DataFrame\n",
    "Avg_SourceData = pd.concat(dataframes, ignore_index=True)\n",
    "print(len(Avg_SourceData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(weather_donghua_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_dict = weather_donghua_df.set_index('formatted_datetime').T.to_dict()\n",
    "\n",
    "# 打印前幾個項目檢查\n",
    "for key, value in list(weather_data_dict.items())[:]:\n",
    "    print(f\"Key: {key}\")\n",
    "    print(f\"Value: {value}\")\n",
    "    print()\n",
    "    \n",
    "print(weather_data_dict['2024010101']['TxSoil0cm'])\n",
    "print(weather_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Avg_SourceData.head())\n",
    "print(Avg_SourceData.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "# count = 0\n",
    "for index, data in Avg_SourceData.iterrows():\n",
    "    print(str(data['DateTime']))\n",
    "    formatted_datetime = str(data['DateTime'])[:10]\n",
    "    \n",
    "    # 檢查 weather_data_dict 是否包含該日期時間\n",
    "    if formatted_datetime in weather_data_dict:\n",
    "        Avg_SourceData.loc[index, 'WSGust'] = weather_data_dict[formatted_datetime]['WSGust']\n",
    "        Avg_SourceData.loc[index, 'WDGust'] = weather_data_dict[formatted_datetime]['WDGust']\n",
    "        Avg_SourceData.loc[index, 'GloblRad'] = weather_data_dict[formatted_datetime]['GloblRad']\n",
    "        Avg_SourceData.loc[index, 'Precp'] = weather_data_dict[formatted_datetime]['Precp']\n",
    "        Avg_SourceData.loc[index, 'TxSoil0cm'] = weather_data_dict[formatted_datetime]['TxSoil0cm']\n",
    "        Avg_SourceData.loc[index, 'TxSoil10cm'] = weather_data_dict[formatted_datetime]['TxSoil10cm']\n",
    "        Avg_SourceData.loc[index, 'TxSoil20cm'] = weather_data_dict[formatted_datetime]['TxSoil20cm']\n",
    "        Avg_SourceData.loc[index, 'TxSoil50cm'] = weather_data_dict[formatted_datetime]['TxSoil50cm']\n",
    "        Avg_SourceData.loc[index, 'TxSoil100cm'] = weather_data_dict[formatted_datetime]['TxSoil100cm']\n",
    "        \n",
    "        print(Avg_SourceData.loc[index,'GloblRad'])\n",
    "        \n",
    "    else:\n",
    "        print(f'{formatted_datetime} not found in weather_data_dict')\n",
    "\n",
    "    count += 1\n",
    "    # if count % 100 == 0:\n",
    "    #     break\n",
    "    print(f'Processing row {count}/{len(Avg_SourceData)}')\n",
    "\n",
    "# 儲存最後的結果\n",
    "Avg_SourceData.to_csv('full_information_Avg_sources_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Avg_SourceData = pd.read_csv('full_information_Avg_sources_data.csv', encoding='utf-8', dtype={\"DateTime\": int})\n",
    "print(Avg_SourceData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示相關性排序(Linear)\n",
    "import pandas as pd\n",
    "\n",
    "# 計算相關係數\n",
    "corr_matrix = Avg_SourceData.corr()\n",
    "sunlight_corr = corr_matrix[\"Sunlight(Lux)\"].sort_values(ascending=False)\n",
    "\n",
    "# 顯示相關性排序\n",
    "print(sunlight_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_list = Avg_SourceData['DateTime'].tolist()\n",
    "# print(Time_list)\n",
    "print(len(Time_list))\n",
    "# print(set(Time_list))\n",
    "# print(len(set(Time_list)))\n",
    "count = 0\n",
    "for i in Time_list:\n",
    "    print(i)\n",
    "    i = str(i)\n",
    "    year_month = i[:6]\n",
    "    day = i[6:8]\n",
    "    yesterday = str(int(day) - 1)\n",
    "    if len(yesterday) == 1:\n",
    "        yesterday = '0' + yesterday\n",
    "    time_loc = i[8:]\n",
    "    new_code = year_month + yesterday + time_loc\n",
    "    print(yesterday,new_code)\n",
    "    if int(new_code) in Time_list:\n",
    "        print('yes')\n",
    "        count += 1\n",
    "    else:\n",
    "        print('no')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Avg_SourceData.set_index(\"DateTime\").T.to_dict()\n",
    "print(result.keys())\n",
    "print(result[20240101090001])\n",
    "print(Avg_SourceData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_list = Avg_SourceData['DateTime'].tolist()\n",
    "# print(Time_list)\n",
    "print(len(Time_list))\n",
    "# print(set(Time_list))\n",
    "# print(len(set(Time_list)))\n",
    "\n",
    "count = 0\n",
    "for index, data in  Avg_SourceData.iterrows():\n",
    "    code = data['DateTime']\n",
    "    # print(code)\n",
    "    code = str(code)\n",
    "    year_month = code[:6]\n",
    "    day = code[6:8]\n",
    "    yesterday = str(int(day) - 1)\n",
    "    if len(yesterday) == 1:\n",
    "        yesterday = '0' + yesterday\n",
    "    time_loc = code[8:14]\n",
    "    new_code = year_month + yesterday + time_loc\n",
    "    print(year_month,day,time_loc)\n",
    "    # print(yesterday,new_code)\n",
    "    new_code = int(new_code)\n",
    "    print(new_code)\n",
    "    if new_code in Time_list:\n",
    "        Avg_SourceData.loc[index,'WindSpeed(m/s)_yes'] = result[int(new_code)]['WindSpeed(m/s)']\n",
    "        Avg_SourceData.loc[index, 'Pressure(hpa)_yes'] = result[int(new_code)]['Pressure(hpa)']\n",
    "        Avg_SourceData.loc[index, 'Temperature(°C)_yes'] = result[int(new_code)]['Temperature(°C)']\n",
    "        Avg_SourceData.loc[index, 'Humidity(%)_yes'] = result[int(new_code)]['Humidity(%)']\n",
    "        Avg_SourceData.loc[index, 'Sunlight(Lux)_yes'] = result[int(new_code)]['Sunlight(Lux)']\n",
    "        Avg_SourceData.loc[index, 'Power(mW)_yes'] = result[int(new_code)]['Power(mW)']\n",
    "        Avg_SourceData.loc[index, 'WSGust_yes'] = result[int(new_code)]['WSGust']\n",
    "        Avg_SourceData.loc[index, 'WDGust_yes'] = result[int(new_code)]['WDGust']\n",
    "        Avg_SourceData.loc[index, 'GloblRad_yes'] = result[int(new_code)]['GloblRad']\n",
    "        Avg_SourceData.loc[index, 'Precp_yes'] = result[int(new_code)]['Precp']\n",
    "        Avg_SourceData.loc[index, 'TxSoil0cm_yes'] = result[int(new_code)]['TxSoil0cm']\n",
    "        Avg_SourceData.loc[index, 'TxSoil10cm_yes'] = result[int(new_code)]['TxSoil10cm']\n",
    "        Avg_SourceData.loc[index, 'TxSoil20cm_yes'] = result[int(new_code)]['TxSoil20cm']\n",
    "        Avg_SourceData.loc[index, 'TxSoil50cm_yes'] = result[int(new_code)]['TxSoil50cm']\n",
    "        Avg_SourceData.loc[index, 'TxSoil100cm_yes'] = result[int(new_code)]['TxSoil100cm']\n",
    "        \n",
    "        count += 1\n",
    "    else:\n",
    "        Avg_SourceData.loc[index,'WindSpeed(m/s)_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'Pressure(hpa)_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'Temperature(°C)_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'Humidity(%)_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'Sunlight(Lux)_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'Power(mW)_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'WSGust_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'WDGust_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'GloblRad_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'Precp_yes'] = -999   \n",
    "        Avg_SourceData.loc[index, 'TxSoil0cm_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'TxSoil10cm_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'TxSoil20cm_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'TxSoil50cm_yes'] = -999\n",
    "        Avg_SourceData.loc[index, 'TxSoil100cm_yes'] = -999\n",
    "        print(f'{new_code} not found in weather_data_dict')\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Avg_SourceData.head())\n",
    "Avg_SourceData.to_csv('full_information_Avg_sources_data_with_yes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Avg_SourceData = pd.read_csv('full_information_Avg_sources_data_with_yes.csv', encoding='utf-8', dtype={\"DateTime\": int})\n",
    "print(len(New_Avg_SourceData))\n",
    "New_Avg_SourceData = New_Avg_SourceData[New_Avg_SourceData['Precp_yes'] != -999]\n",
    "print(len(New_Avg_SourceData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示相關性排序(Linear)\n",
    "import pandas as pd\n",
    "\n",
    "# 計算相關係數\n",
    "corr_matrix = New_Avg_SourceData.corr()\n",
    "sunlight_corr = corr_matrix[\"Sunlight(Lux)\"].sort_values(ascending=False)\n",
    "\n",
    "# 顯示相關性排序\n",
    "print(sunlight_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = New_Avg_SourceData.drop(columns=['DateTime','Power(mW)', 'Sunlight(Lux)','Temperature(°C)','WindSpeed(m/s)','Pressure(hpa)','Humidity(%)']).values\n",
    "\n",
    "# 設定目標為 Sunlight\n",
    "y = New_Avg_SourceData['Sunlight(Lux)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Avg_SourceData = pd.read_csv('full_information_Avg_sources_data_with_yes.csv', encoding='utf-8', dtype={\"DateTime\": int})\n",
    "result = New_Avg_SourceData.set_index(\"DateTime\").T.to_dict()\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[20240102090001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('./CompleteIncompleteAVG')\n",
    "incomplete_data = pd.DataFrame()\n",
    "for i in os.listdir('./CompleteIncompleteAVG'):\n",
    "    if i.endswith('.csv'):\n",
    "        print(i)\n",
    "        df = pd.read_csv('./CompleteIncompleteAVG/'+i, encoding='utf-8')\n",
    "        print(len(df))\n",
    "        incomplete_data = pd.concat([incomplete_data, df], ignore_index=True)\n",
    "print(len(incomplete_data))\n",
    "# incomplete_data = pd.read_csv('full_information_incomplete_data.csv', encoding='utf-8', dtype={\"DateTime\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(incomplete_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_data_dict = incomplete_data.set_index(\"Serial\").T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(incomplete_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in New_Avg_SourceData.iterrows():\n",
    "    code = row['DateTime']\n",
    "    code = str(code)\n",
    "    # print(code[:14])\n",
    "    code = code[:14]\n",
    "    year_month = code[:6]\n",
    "    day = code[6:8]\n",
    "    hour = code[8:10]\n",
    "    minute = code[10:12]\n",
    "    location_code = code[12:]\n",
    "    yes_min = int(minute) - 10\n",
    "    if yes_min < 0:\n",
    "        yes_min = 60 + yes_min\n",
    "        hour = int(hour) - 1\n",
    "        \n",
    "    hour = int(hour)\n",
    "    if yes_min < 10:\n",
    "        yes_min = '0' + str(yes_min)\n",
    "    if hour < 10:\n",
    "        hour = '0' + str(hour)\n",
    "        \n",
    "    # print(hour,yes_min)\n",
    "    new_code = year_month + day + str(hour) + str(yes_min) + location_code\n",
    "    new_code = int(new_code)\n",
    "    print(new_code)\n",
    "    if new_code in result.keys():\n",
    "        New_Avg_SourceData.loc[index, 'Sunlight(Lux)_last_min'] = result[int(new_code)]['Sunlight(Lux)']\n",
    "\n",
    "    else:\n",
    "        if new_code in incomplete_data_dict.keys():\n",
    "            New_Avg_SourceData.loc[index, 'Sunlight(Lux)_last_min'] = incomplete_data_dict[new_code]['Sunlight(Lux)']\n",
    "        else:\n",
    "            New_Avg_SourceData.loc[index, 'Sunlight(Lux)_last_min'] = -999\n",
    "        \n",
    "    yes2_min = int(yes_min) - 10\n",
    "    if yes2_min < 0:\n",
    "        yes2_min = 60 + int(yes2_min)\n",
    "        hour = int(hour) - 1\n",
    "    hour = int(hour)\n",
    "    if yes2_min < 10:\n",
    "        yes2_min = '0' + str(yes2_min)\n",
    "    if hour < 10:\n",
    "        hour = '0' + str(hour)\n",
    "    new_code = year_month + day + str(hour) + str(yes2_min) + location_code\n",
    "    print(new_code)\n",
    "    new_code = int(new_code)\n",
    "    if new_code in result.keys():\n",
    "        New_Avg_SourceData.loc[index, 'Sunlight(Lux)_last_2min'] = result[int(new_code)]['Sunlight(Lux)']\n",
    "\n",
    "    else:\n",
    "        New_Avg_SourceData.loc[index, 'Sunlight(Lux)_last_2min'] = -999\n",
    "        \n",
    "    yes3_min = int(yes2_min) - 10\n",
    "    if yes3_min < 0:\n",
    "        yes3_min = 60 + int(yes3_min)\n",
    "        hour = int(hour) - 1\n",
    "    hour = int(hour)\n",
    "    if yes3_min < 10:\n",
    "        yes3_min = '0' + str(yes3_min)\n",
    "    if hour < 10:\n",
    "        hour = '0' + str(hour)\n",
    "    new_code = year_month + day + str(hour) + str(yes3_min) + location_code\n",
    "    print(new_code)\n",
    "    new_code = int(new_code)\n",
    "    if new_code in result.keys():\n",
    "        New_Avg_SourceData.loc[index, 'Sunlight(Lux)_last_3min'] = result[int(new_code)]['Sunlight(Lux)']\n",
    "\n",
    "    else:\n",
    "        New_Avg_SourceData.loc[index, 'Sunlight(Lux)_last_3min'] = -999\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(New_Avg_SourceData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Avg_SourceData.to_csv('full_information_Avg_sources_data_with_yes_last_min_last2_min_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Avg_SourceData = pd.read_csv('full_information_Avg_sources_data_with_yes_last_min_last2_min_3.csv', encoding='utf-8', dtype={\"DateTime\": int})\n",
    "print(len(Final_Avg_SourceData))\n",
    "Final_Avg_SourceData = Final_Avg_SourceData[Final_Avg_SourceData['Sunlight(Lux)_last_min'] != -999 ]\n",
    "print(len(Final_Avg_SourceData))\n",
    "\n",
    "New_Avg_SourceData = Final_Avg_SourceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in New_Avg_SourceData.iterrows():\n",
    "    location_code = str(row['DateTime'])[12:14]\n",
    "    day = str(row['DateTime'])[6:8]\n",
    "    hour = str(row['DateTime'])[8:10]\n",
    "    minute = str(row['DateTime'])[10:12]\n",
    "    month = str(row['DateTime'])[4:6]\n",
    "    print(location_code)\n",
    "    New_Avg_SourceData.loc[index, 'Location'] = int(location_code)\n",
    "    if int(location_code) in [1,2,3,4,5,6,7,13,14]:\n",
    "        height = 5\n",
    "    elif int(location_code) in [8,9]:\n",
    "        height = 3\n",
    "    elif int(location_code) in [10,11,12,15,16]:\n",
    "        height = 1\n",
    "    elif int(location_code) == 17:\n",
    "        height = 2\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid location code: {location_code}\")\n",
    "    \n",
    "    int_location_code = int(location_code)\n",
    "    if int_location_code == 1:\n",
    "        direction = 181\n",
    "    elif int_location_code == 2:\n",
    "        direction = 175\n",
    "    elif int_location_code == 3:\n",
    "        direction = 180\n",
    "    elif int_location_code == 4:\n",
    "        direction = 161\n",
    "    elif int_location_code == 5 or int_location_code == 6:\n",
    "        direction = 208\n",
    "    elif int_location_code == 7:\n",
    "        direction = 172\n",
    "    elif int_location_code == 8:\n",
    "        direction = 219\n",
    "    elif int_location_code == 9:\n",
    "        direction = 151\n",
    "    elif int_location_code == 10:\n",
    "        direction = 223\n",
    "    elif int_location_code == 11:\n",
    "        direction = 131\n",
    "        \n",
    "    elif int_location_code == 12:\n",
    "        direction = 298\n",
    "    elif int_location_code == 13:\n",
    "        direction = 249\n",
    "    elif int_location_code == 14:\n",
    "        direction = 197\n",
    "    elif int_location_code == 15:\n",
    "        direction = 127\n",
    "    elif int_location_code == 16:\n",
    "        direction = 82\n",
    "    elif int_location_code == 17:\n",
    "        direction = 0\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid location code: {location_code}\")\n",
    "    \n",
    "    direction_x = np.cos(np.radians(direction))\n",
    "    direction_y = np.sin(np.radians(direction))\n",
    "    New_Avg_SourceData.loc[index, 'Height'] = height\n",
    "    # New_Avg_SourceData.loc[index, 'Day'] = int(day)\n",
    "    # New_Avg_SourceData.loc[index, 'Hour'] = int(hour)\n",
    "    New_Avg_SourceData.loc[index, 'Time'] = (int(hour) - 9)*6 + int(minute)/10\n",
    "    New_Avg_SourceData.loc[index, 'Minute'] = int(minute)\n",
    "    New_Avg_SourceData.loc[index, 'Month'] = int(month)\n",
    "    New_Avg_SourceData.loc[index, 'Direction_x'] = direction_x\n",
    "    New_Avg_SourceData.loc[index, 'Direction_y'] = direction_y\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(New_Avg_SourceData.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示相關性排序(Linear)\n",
    "import pandas as pd\n",
    "\n",
    "# 計算相關係數\n",
    "corr_matrix = New_Avg_SourceData.corr()\n",
    "sunlight_corr = corr_matrix[\"Sunlight(Lux)\"].sort_values(ascending=False)\n",
    "\n",
    "# 顯示相關性排序\n",
    "print(sunlight_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(New_Avg_SourceData['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Avg_SourceData_1 = New_Avg_SourceData\n",
    "\n",
    "print(len(New_Avg_SourceData_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clns =   ['WSGust', 'WDGust', 'GloblRad', 'Precp', 'TxSoil0cm', 'TxSoil10cm', 'TxSoil20cm', \n",
    "                   'TxSoil50cm', 'TxSoil100cm', 'WindSpeed(m/s)_yes', \n",
    "                   'Pressure(hpa)_yes', 'Temperature(°C)_yes', 'Humidity(%)_yes', 'Sunlight(Lux)_yes', \n",
    "                   'Power(mW)_yes', 'WSGust_yes', 'WDGust_yes', 'GloblRad_yes', 'Precp_yes', 'TxSoil0cm_yes', 'TxSoil10cm_yes', \n",
    "                   'TxSoil20cm_yes', 'TxSoil50cm_yes', 'TxSoil100cm_yes', 'Sunlight(Lux)_last_min',\n",
    "                   'Sunlight(Lux)_last_2min','Time', 'Minute', 'Direction_x', 'Direction_y', 'Location', 'Height']     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_clns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = New_Avg_SourceData_1['Sunlight(Lux)'].values\n",
    "X = New_Avg_SourceData_1[selected_clns].values\n",
    "print(len(X[0]))\n",
    "print(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge\n",
    "# 假設你的數據是 Regression_X_train 和 Regression_y_train\n",
    "# 使用 MinMaxScaler 來縮放特徵數據\n",
    "# scaler = Regression_MinMaxModel\n",
    "\n",
    "# 先縮放所有特徵\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "# 使用 train_test_split 拆分訓練集和驗證集（例如，80% 訓練，20% 驗證）\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_scaled, test_size=0.0001, random_state=42)\n",
    "\n",
    "model_sunlight = lgb.LGBMRegressor(n_estimators=2500,reg_alpha = 0.8, random_state=42,objective='regression',metric='rmse')\n",
    "\n",
    "# model_sunlight = Ridge(alpha=1.0)\n",
    "model_sunlight.fit(X_train, y_train)\n",
    "\n",
    "# 訓練集 R² 分數\n",
    "r2_train = model_sunlight.score(X_train, y_train)\n",
    "print(f\"Training R squared: {r2_train}\")\n",
    "\n",
    "# 驗證集 R² 分數\n",
    "r2_val = model_sunlight.score(X_val, y_val)\n",
    "print(f\"Validation R squared: {r2_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "y_pred = model_sunlight.predict(X_val)\n",
    "y_pred = scaler_y.inverse_transform(y_pred.reshape(-1, 1))\n",
    "y_val = scaler_y.inverse_transform(y_val.reshape(-1, 1))\n",
    "\n",
    "\n",
    "print(\"mean absolute error:\",mean_absolute_error(y_val,y_pred))\n",
    "print(\"mean squared error:\",mean_squared_error(y_val,y_pred))\n",
    "print(\"root mean squared error:\",np.sqrt(mean_squared_error(y_val,y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New_Avg_SourceData = pd.read_csv('full_information_Avg_sources_data_with_yes.csv', encoding='utf-8', dtype={\"DateTime\": int})\n",
    "New_Avg_SourceData = pd.read_csv('full_information_Avg_sources_data_with_yes_last_min_last2_min_3.csv', encoding='utf-8', dtype={\"DateTime\": int})\n",
    "print(len(New_Avg_SourceData))\n",
    "New_Avg_SourceData = New_Avg_SourceData[New_Avg_SourceData['Power(mW)_yes'] != -999]\n",
    "print(len(New_Avg_SourceData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f = New_Avg_SourceData.drop(columns=['DateTime','Power(mW)','Temperature(°C)','WindSpeed(m/s)','Pressure(hpa)','Humidity(%)','Sunlight(Lux)_last_3min']).values\n",
    "# 設定目標為 Sunlight\n",
    "y_f = New_Avg_SourceData['Power(mW)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_f[0]))\n",
    "print(New_Avg_SourceData.drop(columns=['DateTime','Power(mW)','Temperature(°C)','WindSpeed(m/s)','Pressure(hpa)','Humidity(%)','Sunlight(Lux)_last_3min']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = New_Avg_SourceData.corr()\n",
    "power_corr = corr_matrix[\"Power(mW)\"].sort_values(ascending=False)\n",
    "print(power_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 MinMaxScaler\n",
    "scaler_X_power = MinMaxScaler()\n",
    "scaler_y_power = MinMaxScaler()\n",
    "\n",
    "# 對特徵和目標進行正規化\n",
    "X_scaled = scaler_X_power.fit_transform(X_f)\n",
    "y_scaled = scaler_y_power.fit_transform(y_f.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# 假設你的數據是 Regression_X_train 和 Regression_y_train\n",
    "# 使用 MinMaxScaler 來縮放特徵數據\n",
    "# scaler = Regression_MinMaxModel\n",
    "\n",
    "# # 先縮放所有特徵\n",
    "# X_scaled = scaler.fit_transform(Regression_X_train)\n",
    "\n",
    "# 使用 train_test_split 拆分訓練集和驗證集（例如，80% 訓練，20% 驗證）\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_scaled ,test_size=0.001, random_state=42)\n",
    "\n",
    "# 訓練決策樹回歸模型\n",
    "# model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# model_power = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# model_power = XGBRegressor(\n",
    "#     n_estimators=400,\n",
    "#     random_state=42,\n",
    "#     max_depth=7,\n",
    "# )\n",
    "model_power = lgb.LGBMRegressor(n_estimators=2500, random_state=42,objective='regression',metric='rmse')\n",
    "\n",
    "model_power.fit(X_train, y_train)\n",
    "\n",
    "# 訓練集 R² 分數\n",
    "r2_train = model_power.score(X_train, y_train)\n",
    "print(f\"Training R squared: {r2_train}\")\n",
    "\n",
    "# 驗證集 R² 分數\n",
    "r2_val = model_power.score(X_val, y_val)\n",
    "print(f\"Validation R squared: {r2_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 自定義 R² 的評分函數\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "\n",
    "# 進行 5 折交叉驗證（可以修改 cv 的值）\n",
    "cv_scores = cross_val_score(\n",
    "    model_power, X_scaled, y_scaled, cv=5, scoring=r2_scorer\n",
    ")\n",
    "\n",
    "# 打印每次交叉驗證的分數和平均分數\n",
    "print(f\"Cross-validation R² scores: {cv_scores}\")\n",
    "print(f\"Mean R² score: {np.mean(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model_power.predict(X_val)\n",
    "diff = []\n",
    "# 顯示幾個驗證集的真實值和預測值\n",
    "print(\"\\nSample of Actual vs Predicted values (Validation set):\")\n",
    "print(y_val_pred)\n",
    "for i in range(len(y_val_pred)):  # 顯示前五個結果\n",
    "    actual = scaler_y_power.inverse_transform(y_val[i].reshape(-1, 1))\n",
    "    predicted = scaler_y_power.inverse_transform(y_val_pred[i].reshape(-1, 1))\n",
    "    \n",
    "    # 顯示結果時去掉括號\n",
    "    print(f\"Actual: {actual[0][0]}, Predicted: {predicted[0][0]}\")\n",
    "    \n",
    "    diff.append(abs(actual - predicted))\n",
    "    \n",
    "print(sum(diff)//len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Avg_SourceData = pd.read_csv('full_information_Avg_sources_data_with_yes.csv', encoding='utf-8', dtype={\"DateTime\": int})\n",
    "print(len(New_Avg_SourceData))\n",
    "New_Avg_SourceData = New_Avg_SourceData[New_Avg_SourceData['Precp_yes'] != -999]\n",
    "print(len(New_Avg_SourceData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Avg_SourceData = pd.read_csv('full_information_Avg_sources_data_with_yes.csv', encoding='utf-8', dtype={\"DateTime\": int})\n",
    "print(len(New_Avg_SourceData))\n",
    "# New_Avg_SourceData = New_Avg_SourceData[New_Avg_SourceData['Precp_yes'] != -999]\n",
    "# print(len(New_Avg_SourceData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New_Avg_SourceData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = New_Avg_SourceData.drop(columns=['DateTime','Power(mW)', 'Sunlight(Lux)','Temperature(°C)','WindSpeed(m/s)','Pressure(hpa)','Humidity(%)']).columns\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Avg_SourceData = pd.read_csv('full_information_Avg_sources_data_with_yes_last_min_last2_min_3.csv', encoding='utf-8', dtype={\"DateTime\": int})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Final_Avg_SourceData.set_index(\"DateTime\").T.to_dict()\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(selected_clns))\n",
    "print(selected_clns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataName = os.getcwd()+r'/36_TestSet_SubmissionTemplate/upload(no answer).csv'\n",
    "# DataName = os.getcwd()+r'/full_information_Avg_sources_data_with_yes.csv'\n",
    "# New_Avg_SourceData = pd.read_csv('full_information_Avg_sources_data_with_yes.csv', encoding='utf-8', dtype={\"DateTime\": int})\n",
    "# print(len(New_Avg_SourceData))\n",
    "# SourceData = New_Avg_SourceData[New_Avg_SourceData['Precp_yes'] != -999]\n",
    "# print(len(SourceData))\n",
    "\n",
    "SourceData = pd.read_csv(DataName, encoding='utf-8')\n",
    "target = ['序號']\n",
    "# target = ['DateTime']\n",
    "\n",
    "EXquestion = SourceData[target].values\n",
    "\n",
    "inputs = [] #存放參考資料\n",
    "PredictOutput = [] #存放預測值(天氣參數)\n",
    "PredictPower = [] #存放預測值(發電量) \n",
    "Serial_list = [] #存放序號\n",
    "\n",
    "count = 0\n",
    "data = []\n",
    "\n",
    "# columns = [\n",
    "#     'WSGust', 'WDGust', 'GloblRad', 'Precp', 'TxSoil0cm', 'TxSoil10cm',\n",
    "#     'TxSoil20cm', 'TxSoil50cm', 'TxSoil100cm', 'WindSpeed(m/s)_yes', 'Pressure(hpa)_yes', \n",
    "#     'Temperature(°C)_yes', 'Humidity(%)_yes', 'Sunlight(Lux)_yes', 'Power(mW)_yes', 'WSGust_yes', \n",
    "#     'WDGust_yes', 'GloblRad_yes', 'Precp_yes', 'TxSoil0cm_yes', 'TxSoil10cm_yes', \n",
    "#     'TxSoil20cm_yes', 'TxSoil50cm_yes', 'TxSoil100cm_yes','Sunlight(Lux)_last_min','Sunlight(Lux)_last_2min','Sunlight(Lux)_last_3min'\n",
    "# ]\n",
    "columns = selected_clns\n",
    "# 創建空的 DataFrame\n",
    "result_df = pd.DataFrame(columns=columns)\n",
    "sunlight_tmp_dict = {}\n",
    "for qs in EXquestion:\n",
    "    key = str(qs[0])[:10]\n",
    "    print(key)  \n",
    "    # 'WSGust', 'WDGust', 'GloblRad', 'Precp', 'TxSoil0cm', 'TxSoil10cm',\n",
    "    #    'TxSoil20cm', 'TxSoil50cm', 'TxSoil100cm'\n",
    "    data = [weather_data_dict[key]['WSGust'],weather_data_dict[key]['WDGust'],weather_data_dict[key]['GloblRad'],weather_data_dict[key]['Precp'],weather_data_dict[key]['TxSoil0cm'],weather_data_dict[key]['TxSoil10cm'],weather_data_dict[key]['TxSoil20cm'],weather_data_dict[key]['TxSoil50cm'],weather_data_dict[key]['TxSoil100cm']]\n",
    "    # print(data)\n",
    "    code = qs[0]\n",
    "    code = str(code)\n",
    "    year_month = code[:6]\n",
    "    day = code[6:8]\n",
    "    yesterday = str(int(day) - 1)\n",
    "    if len(yesterday) == 1:\n",
    "        yesterday = '0' + yesterday\n",
    "    time_loc = code[8:14]\n",
    "    new_code = year_month + yesterday + time_loc\n",
    "    print(year_month,day,time_loc)\n",
    "    # print(yesterday,new_code)\n",
    "    new_code = int(new_code)\n",
    "    print(\"yesterday\",new_code)\n",
    "    # 'WindSpeed(m/s)_yes',\n",
    "    #    'Pressure(hpa)_yes', 'Temperature(°C)_yes', 'Humidity(%)_yes',\n",
    "    #    'Sunlight(Lux)_yes', 'Power(mW)_yes', 'WSGust_yes', 'WDGust_yes',\n",
    "    #    'GloblRad_yes', 'Precp_yes', 'TxSoil0cm_yes', 'TxSoil10cm_yes',\n",
    "    #    'TxSoil20cm_yes', 'TxSoil50cm_yes', 'TxSoil100cm_yes'],\n",
    "    if new_code in result.keys():\n",
    "        data.append(result[new_code]['WindSpeed(m/s)'])\n",
    "        data.append(result[new_code]['Pressure(hpa)'])\n",
    "        data.append(result[new_code]['Temperature(°C)'])\n",
    "        data.append(result[new_code]['Humidity(%)'])\n",
    "        data.append(result[new_code]['Sunlight(Lux)'])\n",
    "        data.append(result[new_code]['Power(mW)'])\n",
    "        data.append(result[new_code]['WSGust'])\n",
    "        data.append(result[new_code]['WDGust'])\n",
    "        data.append(result[new_code]['GloblRad'])\n",
    "        data.append(result[new_code]['Precp'])\n",
    "        data.append(result[new_code]['TxSoil0cm'])\n",
    "        data.append(result[new_code]['TxSoil10cm'])\n",
    "        data.append(result[new_code]['TxSoil20cm'])\n",
    "        data.append(result[new_code]['TxSoil50cm'])\n",
    "        data.append(result[new_code]['TxSoil100cm'])\n",
    "        # data.append(result[new_code]['Sunlight(Lux)_last_min'])\n",
    "        # data.append(result[new_code]['Sunlight(Lux)_last_2min'])\n",
    "    else:\n",
    "        raise Exception(f'{new_code} not found in result_dict')\n",
    "    \n",
    "    code = code[:14]\n",
    "    year_month = code[:6]\n",
    "    day = code[6:8]\n",
    "    hour = code[8:10]\n",
    "    minute = code[10:12]\n",
    "    location_code = code[12:]\n",
    "    yes_min = int(minute) - 10\n",
    "    if yes_min < 0:\n",
    "        yes_min = 60 + yes_min\n",
    "        hour = int(hour) - 1\n",
    "        \n",
    "    hour = int(hour)\n",
    "    if yes_min < 10:\n",
    "        yes_min = '0' + str(yes_min)\n",
    "    if hour < 10:\n",
    "        hour = '0' + str(hour)\n",
    "        \n",
    "    # print(hour,yes_min)\n",
    "    new_code = year_month + day + str(hour) + str(yes_min) + location_code\n",
    "    new_code = int(new_code)\n",
    "    print(\"last_min\",new_code)\n",
    "    if new_code in result.keys():\n",
    "        data.append(result[new_code]['Sunlight(Lux)_last_min'])\n",
    "    else:\n",
    "        if new_code in incomplete_data_dict.keys():\n",
    "            data.append(incomplete_data_dict[new_code]['Sunlight(Lux)'])\n",
    "        else:\n",
    "            data.append(-999)\n",
    "    \n",
    "    yes2_min = int(yes_min) - 10\n",
    "    if yes2_min < 0:\n",
    "        yes2_min = 60 + int(yes2_min)\n",
    "        hour = int(hour) - 1\n",
    "    hour = int(hour)\n",
    "    if yes2_min < 10:\n",
    "        yes2_min = '0' + str(yes2_min)\n",
    "    if hour < 10:\n",
    "        hour = '0' + str(hour)\n",
    "    new_code = year_month + day + str(hour) + str(yes2_min) + location_code\n",
    "    print(\"last2_min\",new_code)\n",
    "    new_code = int(new_code)\n",
    "    if new_code in result.keys():\n",
    "        data.append(result[new_code]['Sunlight(Lux)_last_2min'])\n",
    "    else:\n",
    "        if new_code in incomplete_data_dict.keys():\n",
    "            data.append(incomplete_data_dict[new_code]['Sunlight(Lux)'])\n",
    "        else:\n",
    "            data.append(-999)\n",
    "            # raise Exception(f'{new_code} not found in result_dict')\n",
    "            \n",
    "    # yes3_min = int(yes2_min) - 10\n",
    "    # if yes3_min < 0:\n",
    "    #     yes3_min = 60 + int(yes3_min)\n",
    "    #     hour = int(hour) - 1    \n",
    "    # hour = int(hour)\n",
    "    # if yes3_min < 10:\n",
    "    #     yes3_min = '0' + str(yes3_min)\n",
    "    # if hour < 10:\n",
    "    #     hour = '0' + str(hour)\n",
    "    # new_code = year_month + day + str(hour) + str(yes3_min) + location_code\n",
    "    # print(\"last3_min\",new_code)\n",
    "    # new_code = int(new_code)\n",
    "    # if new_code in result.keys():\n",
    "    #     data.append(result[new_code]['Sunlight(Lux)_last_3min'])\n",
    "    # else:\n",
    "    #     if new_code in incomplete_data_dict.keys():\n",
    "    #         data.append(incomplete_data_dict[new_code]['Sunlight(Lux)'])\n",
    "    #     else:\n",
    "    #         data.append(-999)\n",
    "    #         # raise Exception(f'{new_code} not found in result_dict')\n",
    "    code = str(qs[0])\n",
    "    location_code = code[12:14]\n",
    "    day = code[6:8]\n",
    "    hour = code[8:10]\n",
    "    minute = code[10:12]\n",
    "    month = code[4:6]\n",
    "    print(location_code)\n",
    "    New_Avg_SourceData.loc[index, 'Location'] = int(location_code)\n",
    "    if int(location_code) in [1,2,3,4,5,6,7,13,14]:\n",
    "        height = 5\n",
    "    elif int(location_code) in [8,9]:\n",
    "        height = 3\n",
    "    elif int(location_code) in [10,11,12,15,16]:\n",
    "        height = 1\n",
    "    elif int(location_code) == 17:\n",
    "        height = 2\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid location code: {location_code}\")\n",
    "    \n",
    "    int_location_code = int(location_code)\n",
    "    if int_location_code == 1:\n",
    "        direction = 181\n",
    "    elif int_location_code == 2:\n",
    "        direction = 175\n",
    "    elif int_location_code == 3:\n",
    "        direction = 180\n",
    "    elif int_location_code == 4:\n",
    "        direction = 161\n",
    "    elif int_location_code == 5 or int_location_code == 6:\n",
    "        direction = 208\n",
    "    elif int_location_code == 7:\n",
    "        direction = 172\n",
    "    elif int_location_code == 8:\n",
    "        direction = 219\n",
    "    elif int_location_code == 9:\n",
    "        direction = 151\n",
    "    elif int_location_code == 10:\n",
    "        direction = 223\n",
    "    elif int_location_code == 11:\n",
    "        direction = 131\n",
    "        \n",
    "    elif int_location_code == 12:\n",
    "        direction = 298\n",
    "    elif int_location_code == 13:\n",
    "        direction = 249\n",
    "    elif int_location_code == 14:\n",
    "        direction = 197\n",
    "    elif int_location_code == 15:\n",
    "        direction = 127\n",
    "    elif int_location_code == 16:\n",
    "        direction = 82\n",
    "    elif int_location_code == 17:\n",
    "        direction = 0\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid location code: {location_code}\")\n",
    "    \n",
    "    direction_x = np.cos(np.radians(direction))\n",
    "    direction_y = np.sin(np.radians(direction))\n",
    "    'Time', 'Minute', 'Direction_x', 'Direction_y', 'Location', 'Height'\n",
    "    data.append((int(hour) - 9)*6 + int(minute)/10)\n",
    "    data.append(int(minute))\n",
    "    data.append(direction_x)\n",
    "    data.append(direction_y)\n",
    "    data.append(int_location_code)\n",
    "    data.append(height)\n",
    "    \n",
    "    print(data)\n",
    "    print(len(data))\n",
    "    result_df.loc[len(result_df)] = data\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result_df.head(100))\n",
    "print(result_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假設 result_df 是你的輸入數據框\n",
    "X_sunlight = result_df.values\n",
    "X_with_prev = []\n",
    "# 初始化一個變量存儲結果\n",
    "y_sunlight_pred_list = []\n",
    "\n",
    "# 初始值，假設第一筆資料不需要任何依賴\n",
    "prev_prediction = 0  \n",
    "\n",
    "for i in range(len(X_sunlight)):\n",
    "    # 在原始輸入數據上添加前一筆預測結果\n",
    "    # 假設預測結果需要添加為額外的特徵\n",
    "    X_with_prev = X_sunlight[i]\n",
    "\n",
    "    if i % 48 == 0 :\n",
    "        pass\n",
    "        # X_with_prev = X_sunlight[i]\n",
    "    elif i % 48 == 1:\n",
    "        # print(len(X_with_prev))\n",
    "        X_with_prev[len(X_with_prev)-8] = y_sunlight_pred_list[-1]\n",
    "    else:\n",
    "        X_with_prev[len(X_with_prev)-8] = y_sunlight_pred_list[-1]\n",
    "        X_with_prev[len(X_with_prev)-7] = y_sunlight_pred_list[-2]\n",
    "    # else:\n",
    "    #     raise ValueError(f\"Invalid index: {i}\")\n",
    "        # X_with_prev[len(X_with_prev)-3] = y_sunlight_pred_list[-1]\n",
    "        # X_with_prev[len(X_with_prev)-2] = y_sunlight_pred_list[-2]\n",
    "        # X_with_prev[len(X_with_prev)-1] = y_sunlight_pred_list[-3]\n",
    "        \n",
    "    # 標準化輸入數據\n",
    "    X_with_prev = np.array(X_with_prev).reshape(1, -1)\n",
    "    X_scaled = scaler_X.transform(X_with_prev)\n",
    "    \n",
    "    # 預測當前輸出\n",
    "    y_pred_scaled = model_sunlight.predict(X_scaled)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "    \n",
    "    # 存儲結果\n",
    "    y_sunlight_pred_list.append(y_pred[0][0])\n",
    "    \n",
    "    # 更新前一筆預測結果\n",
    "    prev_prediction = y_pred[0][0]\n",
    "\n",
    "# 將結果轉為 NumPy array 或其他需要的格式\n",
    "y_sunlight_pred = np.array(y_sunlight_pred_list)\n",
    "print(y_sunlight_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_sunlight_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.columns)\n",
    "result_df.insert(0,'Sunlight(Lux)',y_sunlight_pred)\n",
    "print(result_df.columns)\n",
    "print(result_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_power = result_df.drop(columns=['Time','Minute','Direction_x','Direction_y','Location','Height']).values\n",
    "\n",
    "# 使用 MinMaxScaler 來縮放特徵數據\n",
    "scaler_X_power = MinMaxScaler()\n",
    "X_power_scaled = scaler_X_power.fit_transform(X_power)\n",
    "\n",
    "# 預測功率（power）\n",
    "y_power_pred_scaled = model_power.predict(X_power_scaled)\n",
    "\n",
    "# 逆縮放功率預測結果\n",
    "y_power_pred = scaler_y_power.inverse_transform(y_power_pred_scaled.reshape(-1, 1))\n",
    "\n",
    "# 將功率預測結果轉為正數(如果預測結果為負數，將其設置為 0)\n",
    "for i in range(len(y_power_pred)):\n",
    "    if y_power_pred[i][0] < 0:\n",
    "        y_power_pred[i][0] = 0\n",
    "\n",
    "# 將功率預測結果加到數據集中\n",
    "result_df['Predicted_Power'] = y_power_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.head(50))\n",
    "result_df['Predicted_Power'] = result_df['Predicted_Power'].apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EXquestion)\n",
    "print(result_df['Predicted_Power'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff = 0\n",
    "# for i in range(len(SourceData)):\n",
    "#     # print(EXquestion[i][0], result_df['Predicted_Power'].values[i])\n",
    "#     # print(SourceData.iloc[i]['DateTime'], SourceData.iloc[i]['Power(mW)'])\n",
    "#     print(SourceData.iloc[i]['Power(mW)'],result_df['Predicted_Power'].values[i])\n",
    "#     diff += abs(SourceData.iloc[i]['Power(mW)'] - result_df['Predicted_Power'].values[i])\n",
    "    \n",
    "# print(diff/len(SourceData))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('data_ouput_check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Serial_list = []\n",
    "for qs in EXquestion:\n",
    "    Serial_list.append(qs[0])\n",
    "print(Serial_list)\n",
    "df = pd.DataFrame({'序號':Serial_list,'答案':result_df['Predicted_Power'].values})\n",
    "# 將 DataFrame 寫入 CSV 檔案\n",
    "df.to_csv('upload_check.csv', index=False) \n",
    "print('Output CSV File Saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AICUP_PG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
